// Signature file for parser generated by fsyacc
module PrologParser
type token = 
  | EOF
  | DOT
  | COMMA
  | MINUS
  | COLON
  | RIGHT_BRACK
  | LEFT_BRACK
  | RIGHT_BRACKET
  | LEFT_BRACKET
  | NULL
  | FALSE
  | TRUE
  | IS
  | STRING of (string)
  | VAR of (string)
  | ATOM of (string)
  | INT of (int)
type tokenId = 
    | TOKEN_EOF
    | TOKEN_DOT
    | TOKEN_COMMA
    | TOKEN_MINUS
    | TOKEN_COLON
    | TOKEN_RIGHT_BRACK
    | TOKEN_LEFT_BRACK
    | TOKEN_RIGHT_BRACKET
    | TOKEN_LEFT_BRACKET
    | TOKEN_NULL
    | TOKEN_FALSE
    | TOKEN_TRUE
    | TOKEN_IS
    | TOKEN_STRING
    | TOKEN_VAR
    | TOKEN_ATOM
    | TOKEN_INT
    | TOKEN_end_of_input
    | TOKEN_error
type nonTerminalId = 
    | NONTERM__startstart
    | NONTERM_start
    | NONTERM_prog
    | NONTERM_fact
    | NONTERM_rule
    | NONTERM_signature
    | NONTERM_parameter
    | NONTERM_parameterList
    | NONTERM_body
    | NONTERM_calcExpr
/// This function maps tokens to integer indexes
val tagOfToken: token -> int

/// This function maps integer indexes to symbolic token ids
val tokenTagToTokenId: int -> tokenId

/// This function maps production indexes returned in syntax errors to strings representing the non terminal that would be produced by that production
val prodIdxToNonTerminal: int -> nonTerminalId

/// This function gets the name of a token as a string
val token_to_string: token -> string
val start : (Microsoft.FSharp.Text.Lexing.LexBuffer<'cty> -> token) -> Microsoft.FSharp.Text.Lexing.LexBuffer<'cty> -> (Solve.Rule.Rule option) 
